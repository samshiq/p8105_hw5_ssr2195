---
title: "Homework 5"
author: "Samina Rashiq"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1
```{r problem_1}

#Set seed for reproducibility
set.seed(4200)

# Create birthday simulation function
bday_sim = function(n) {
  bdays = sample(1:365, size = n, replace = TRUE)
  duplicate = length(unique(bdays)) < n
  return(duplicate)
}

# Run simulation from for group sizes between 2-50 10000 times
sim_res = 
  expand_grid(
    n = 2:50,
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
  summarize(prob = mean(res))

# Plot probability as a function of group size
sim_res |> 
  ggplot(aes(x = n, y = prob )) + 
  geom_line()
```


As group size increases, the probability that two people in the group share the same birthday increases as well. 

## Problem 2
```{r}

# Set seed for reproducibility
set.seed(1738)

# Set design elements
n <- 30       # Sample size
std_dev <- 5  # Standard deviation
hypotheses <- c(0, 1, 2, 3, 4, 5, 6)  # Hypothesized means

# Generate datasets for each true mean
datasets <- expand_grid(
  dataset_id = 1:5000,
  true_mean = hypotheses
) %>%
  mutate(data = map(true_mean, ~ rnorm(n, mean = .x, sd = std_dev)))

# Perform t-tests and compute sample means and p-values
t_test_results <- datasets %>%
  mutate(
    mu_hat = map_dbl(data, mean),                            
    p_value = map_dbl(data, ~ t.test(.x, mu = 0)$p.value)
  )

```

```{r}
# Calculate power for each true mean
power_results <- t_test_results %>%
  group_by(true_mean) %>%
  summarize(power = mean(p_value < 0.05), .groups = "drop")  # Proportion of rejections

# Plot power versus true mean
plot_power <- ggplot(power_results, aes(x = true_mean, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of the Test vs. True Mean",
    x = "True Mean (mu)",
    y = "Power (Proportion of Null Rejections)"
  ) +
  theme_minimal()

print(plot_power)

```

```{r}
# Calculate average mu_hat for all datasets
average_mu_results <- t_test_results %>%
  group_by(true_mean) %>%
  summarize(avg_mu_hat = mean(mu_hat), .groups = "drop")

# Calculate average mu_hat for rejected samples only
average_mu_rejected <- t_test_results %>%
  filter(p_value < 0.05) %>%
  group_by(true_mean) %>%
  summarize(avg_mu_rejected = mean(mu_hat), .groups = "drop")

# Combine overall and rejected averages for combined plot
combined_results <- average_mu_results %>%
  left_join(average_mu_rejected, by = "true_mean")



# Plot average mu_hat vs true mean
plot_avg_mu <- ggplot(average_mu_results, aes(x = true_mean, y = avg_mu_hat)) +
  geom_line(color = "deeppink", size = 1) +  # Add deep pink to the line
  geom_point(color = "deeppink", size = 2) +  # Add deep pink to the points
  labs(
    title = "Average Estimate of Mu vs True Mean",
    x = "True Mean (mu)",
    y = "Average Estimate of mu"
  ) +
  theme_minimal()

print(plot_avg_mu)


# Plot overall average vs rejected sample average
plot_combined <- ggplot(combined_results, aes(x = true_mean)) +
  geom_line(aes(y = avg_mu_hat, color = "Overall Average"), size = 1) +
  geom_point(aes(y = avg_mu_hat, color = "Overall Average")) +
  geom_line(aes(y = avg_mu_rejected, color = "Rejected Samples"), size = 1) +
  geom_point(aes(y = avg_mu_rejected, color = "Rejected Samples")) +
  scale_color_manual(values = c("Overall Average" = "deeppink", "Rejected Samples" = "hotpink")) +
  labs(
    title = "Average Estimate of mû vs True Mean",
    x = "True Mean (mu)",
    y = "Average Estimate of mû",
    color = "Legend"
  ) +
  theme_minimal()

print(plot_combined)

```


No, the sample average of mu-hat from rejected tests is not approximately equal to the true value of mu, especially when mu is small. This is because we only reject the null hypothesis when the estimate mu-hat is more extreme, which leads to a higher average for rejected samples.

However, as mu gets larger, the rejected-samples average (blue line) approaches the true value (black line) because we are rejecting the null hypothesis more frequently. This means we’re including nearly all samples, not just the extreme ones, which reduces the bias.



## Problem 3
```{r }

```




